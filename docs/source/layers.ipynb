{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c58117f",
   "metadata": {},
   "source": [
    "# Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed66e148",
   "metadata": {},
   "source": [
    "The most general layers in `kgcnn` take normal and ragged tensor as input. The graph oriented operations are im\n",
    "\n",
    "\n",
    "1. The most general layers that kept maintained beyond different models with proper documentation are located in `kgcnn.layers`. These are:\n",
    "    * `kgcnn.layers.attention` Layers for graph attention.\n",
    "    * `kgcnn.layers.casting` Layers for casting tensor formats.\n",
    "    * `kgcnn.layers.conv` Basic convolution layers.\n",
    "    * `kgcnn.layers.gather` Layers around tf.gather.\n",
    "    * `kgcnn.layers.geom` Geometry operations.\n",
    "    * `kgcnn.layers.message` Message passing base layer.\n",
    "    * `kgcnn.layers.mlp` Multi-layer perceptron for graphs.\n",
    "    * `kgcnn.layers.modules` Keras layers and modules to support ragged tensor input.\n",
    "    * `kgcnn.layers.norm` Normalization layers for graph tensors.\n",
    "    * `kgcnn.layers.pooling` General layers for standard aggregation and pooling.\n",
    "    * `kgcnn.layers.relational` Relational message processing.\n",
    "    * `kgcnn.layers.set2set` Set2Set type architectures for e.g. pooling nodes.\n",
    "    * `kgcnn.layers.update` Some node/edge update layers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9a59ab",
   "metadata": {},
   "source": [
    "> **NOTE**: Please check https://kgcnn.readthedocs.io/en/latest/kgcnn.layers.html for documentation of each layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35de5004",
   "metadata": {},
   "source": [
    "## Implementaion details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc229b02",
   "metadata": {},
   "source": [
    "Most tensorflow methods already support ragged tensors, which can be looked up here: https://www.tensorflow.org/api_docs/python/tf/ragged. \n",
    "\n",
    "For using keras layers, most layers in `kgcnn` inherit from `kgcnn.layers.base.GraphBaseLayer` which adds some utility methods and arguments, such as the `ragged_validate` parameter that is used for ragged tensor creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49ec83af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from kgcnn.layers.base import GraphBaseLayer\n",
    "\n",
    "class NewLayer(GraphBaseLayer):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def call(self, inputs, **kwargs):\n",
    "        # Do something in call.\n",
    "        return inputs\n",
    "\n",
    "new_layer = NewLayer(ragged_validate=False)\n",
    "print(new_layer._supports_ragged_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c664a24",
   "metadata": {},
   "source": [
    "Since ragged tensors can result in quite a performance loss due to shape checks of ragged dimensions on runtime, it is recommended to directly work with the values tensor/information (if possible) and to use `ragged_validate` to `False` in production. An example is the `tf.ragged.map_flat_values` method.\n",
    "\n",
    "Utility methods of `GraphBaseLayer` to work with values directly are `assert_ragged_input_rank` and `map_values` . Note that this can speed up models and is essentially equal to a disjoint graph tensor representation. \n",
    "However, with ragged tensors there is also the possibility to try `tf.vectorized_map` or `tf.map_fn` if values can not be accessed.\n",
    "\n",
    "Here is an example of how to use `assert_ragged_input_rank` and `map_values` . With `assert_ragged_input_rank` it can be ensured that a ragged tensor is given in `call` by casting padded+mask or normal tensor (for example in case of equal sized graphs) to a ragged version, in order to accesss e.g. `inputs.values` etc.\n",
    "With `map_values` a function can be directly applied to the values tensor or a list of value tensors. Axis argument can refer to the ragged tensor shape but the `map_values` is restricted to ragged rank of one. Fallback for `map_values` is applying the function directly to its input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a02b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewLayer(GraphBaseLayer):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def call_v1(self, inputs, **kwargs):\n",
    "        inputs = self.assert_ragged_input_rank(inputs, ragged_rank=1)\n",
    "        return tf.RaggedTensor.from_row_splits(\n",
    "            tf.exp(inputs.values), inputs.row_splits, validate=self.ragged_validate)\n",
    "\n",
    "    def call_v2(self, inputs, **kwargs):\n",
    "        # Possible kwargs for function can be added. Can have axis argument (special case).\n",
    "        return self.map_values(tf.exp, inputs)\n",
    "    \n",
    "new_layer = NewLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4699f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (v1): (2, 3, 4) (2, None, 4)\n",
      "x (v2): (2, 3, 4) (2, 3, 4)\n",
      "x_ragged (v1): (2, None, 4) (2, None, 4)\n",
      "x_ragged (v2): (2, None, 4) (2, None, 4)\n"
     ]
    }
   ],
   "source": [
    "x = tf.ones((2, 3, 4))\n",
    "x_ragged = tf.ragged.constant([[[1.0, 1.0, 1.0, 1.0]],[[1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0]]], ragged_rank=1)\n",
    "\n",
    "print(\"x (v1):\", x.shape, new_layer.call_v1(x).shape)\n",
    "print(\"x (v2):\", x.shape, new_layer.call_v2(x).shape)\n",
    "print(\"x_ragged (v1):\", x_ragged.shape, new_layer.call_v1(x_ragged).shape)\n",
    "print(\"x_ragged (v2):\", x_ragged.shape, new_layer.call_v2(x_ragged).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432360ab",
   "metadata": {},
   "source": [
    "> **NOTE**: You can find this page as jupyter notebook in https://github.com/aimat-lab/gcnn_keras/tree/master/docs/source"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
