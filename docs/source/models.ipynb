{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "183317fb",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32271643",
   "metadata": {},
   "source": [
    "The most frequent usage for graph convolutions is either node or graph classification. As for their size, either a single large graph, e.g. citation network or small (batched) graphs like molecules have to be considered. \n",
    "\n",
    "Graphs can be represented by an index list of connections plus feature information. Typical quantities in tensor format to describe a graph are listed below.\n",
    "\n",
    "* `nodes`: Node-list of shape `(batch, [N], F)` where `N` is the number of nodes and `F` is the node feature dimension.\n",
    "* `edges`: Edge-list of shape `(batch, [M], F)` where `M` is the number of edges and `F` is the edge feature dimension.\n",
    "* `indices`: Connection-list of shape `(batch, [M], 2)` where `M` is the number of edges. The indices denote a connection of incoming or receiving node `i` and outgoing or sending node `j` as `(i, j)`.\n",
    "* `state`: Graph state information of shape `(batch, F)` where `F` denotes the feature dimension.\n",
    " \n",
    "A major issue for graphs is their flexible size and shape, when using mini-batches. \n",
    "Here in `kgcnn` , for a graph implementation in the spirit of keras, the batch dimension should be kept also in between layers. This is realized by using `RaggedTensor` for the graph properties and indices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abeed6f0",
   "metadata": {},
   "source": [
    "Graph tensors for edge-indices or attributes for multiple graphs is passed to the model in form of ragged tensors \n",
    "of shape `(batch, None, Dim)` where `Dim` denotes a fixed feature or index dimension.\n",
    "Such a ragged tensor has `ragged_rank=1` with one ragged dimension indicated by `None` and is build from a value plus partition tensor.\n",
    "\n",
    "For example, the graph structure is represented by an index-list of shape `(batch, None, 2)` with index of incoming or receiving node `i` and outgoing or sending node `j` as `(i, j)`.\n",
    "Note, an additional edge with `(j, i)` is required for undirected graphs. \n",
    "A ragged constant can be easily created and passed to a model either with `tf.RaggedTensor` methods or via a simple `tf.ragged.constant` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01eb1852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, None, 3) <dtype: 'float32'>\n",
      "(3, None, 2) <dtype: 'int64'>\n",
      "(3, 1) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "nodes = [[[0.0, 1.0, 0.0], [0.0, 0.0, 2.0]], [[0.0, 1.0, 2.0], [0.0, 0.0, 0.0], [1.0, 1.0, 3.0]], [[0.0, 0.0, 0.0]]]\n",
    "idx = [[[0, 1], [1, 0]], [[0, 1], [1, 2], [2, 0]], [[0, 0]]]\n",
    "labels = [[1.0], [0.0], [0.0]]  # batch_size=3\n",
    "\n",
    "# Get ragged tensor of shape (3, None, 3) for node_input\n",
    "node_input = tf.ragged.constant(nodes, ragged_rank=1, inner_shape=(3, ), dtype=\"float32\")\n",
    "node_input = tf.RaggedTensor.from_row_lengths(np.concatenate(nodes, dtype=\"float32\"), [len(i) for i in nodes])\n",
    "print(node_input.shape, node_input.dtype)\n",
    "\n",
    "# Get ragged tensor of shape (3, None, 2) for indices\n",
    "edge_index_input = tf.ragged.constant(idx, ragged_rank=1, inner_shape=(2, ), dtype=\"int64\")\n",
    "edge_index_input = tf.RaggedTensor.from_row_lengths(np.concatenate(idx, dtype=\"int64\"), [len(i) for i in idx])\n",
    "print(edge_index_input.shape, edge_index_input.dtype)\n",
    "\n",
    "# Labels. No ragged dimension needed.\n",
    "graph_labels = tf.constant(labels, dtype=\"float32\")\n",
    "print(graph_labels.shape, graph_labels.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4447793",
   "metadata": {},
   "source": [
    "## Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a409c5e0",
   "metadata": {},
   "source": [
    "Like most models in `kgcnn.literature` the models can be set up with the `tf.keras` functional API. Here an example for a simple message passing GNN. The layers are taken from `kgcnn.layers` . See documentation of layers for further details.\n",
    "\n",
    "Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "997de73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " node_input (InputLayer)        [(None, None, 3)]    0           []                               \n",
      "                                                                                                  \n",
      " edge_index_input (InputLayer)  [(None, None, 2)]    0           []                               \n",
      "                                                                                                  \n",
      " gather_embedding_selection (Ga  [(None, None, 3),   0           ['node_input[0][0]',             \n",
      " therEmbeddingSelection)         (None, None, 3)]                 'edge_index_input[0][0]']       \n",
      "                                                                                                  \n",
      " dense_embedding (DenseEmbeddin  (None, None, 10)    40          ['gather_embedding_selection[0][1\n",
      " g)                                                              ]']                              \n",
      "                                                                                                  \n",
      " pooling_local_edges (PoolingLo  (None, None, 10)    0           ['node_input[0][0]',             \n",
      " calEdges)                                                        'dense_embedding[0][0]',        \n",
      "                                                                  'edge_index_input[0][0]']       \n",
      "                                                                                                  \n",
      " lazy_concatenate (LazyConcaten  (None, None, 13)    0           ['node_input[0][0]',             \n",
      " ate)                                                             'pooling_local_edges[0][0]']    \n",
      "                                                                                                  \n",
      " dense_embedding_1 (DenseEmbedd  (None, None, 1)     14          ['lazy_concatenate[0][0]']       \n",
      " ing)                                                                                             \n",
      "                                                                                                  \n",
      " pooling_embedding (PoolingEmbe  (None, 1)           0           ['dense_embedding_1[0][0]']      \n",
      " dding)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 54\n",
      "Trainable params: 54\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from kgcnn.layers.gather import GatherNodesSelection\n",
    "from kgcnn.layers.modules import Dense, LazyConcatenate  # ragged support\n",
    "from kgcnn.layers.pooling import PoolingLocalMessages, PoolingNodes\n",
    "\n",
    "ks = tf.keras\n",
    "\n",
    "n = ks.layers.Input(shape=(None, 3), name='node_input', dtype=\"float32\", ragged=True)\n",
    "ei = ks.layers.Input(shape=(None, 2), name='edge_index_input', dtype=\"int64\", ragged=True)\n",
    "\n",
    "n_in, n_out  = GatherNodesSelection([0, 1])([n, ei])\n",
    "node_messages = Dense(10, activation='relu')(n_out)\n",
    "node_updates = PoolingLocalMessages()([n, node_messages, ei])\n",
    "n_node_updates = LazyConcatenate(axis=-1)([n, node_updates])\n",
    "n_embedding = Dense(1)(n_node_updates)\n",
    "g_embedding = PoolingNodes()(n_embedding)\n",
    "\n",
    "message_functional = ks.models.Model(inputs=[n, ei], outputs=g_embedding)\n",
    "message_functional.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96464117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 654ms/step\n",
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "out = message_functional.predict([node_input, edge_index_input])\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647d81b1",
   "metadata": {},
   "source": [
    "## Subclassing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fe0f2f",
   "metadata": {},
   "source": [
    "A model can be constructed by subclassing from `tf.keras.Model` where the call method must be implemented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71f345f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGNN(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, units=10):\n",
    "        super(SimpleGNN, self).__init__()\n",
    "        self.gather = GatherNodesSelection([0, 1])\n",
    "        self.message = Dense(units, activation='relu')\n",
    "        self.aggregate = PoolingLocalMessages()\n",
    "        self.concat = LazyConcatenate(axis=-1)\n",
    "        self.classifier = Dense(1)\n",
    "        self.pooling = PoolingNodes()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        n, ei = inputs\n",
    "        n_in, n_out = self.gather([n, ei])\n",
    "        node_messages = self.message(n_out)\n",
    "        node_updates = self.aggregate([n, node_messages, ei])\n",
    "        n_node_updates = self.concat([n, node_updates])\n",
    "        n_embedding = self.classifier(n_node_updates)\n",
    "        g_embedding = self.pooling(n_embedding)\n",
    "        return g_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b90e1a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 342ms/step\n",
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "model_subclass = SimpleGNN()\n",
    "out = model_subclass.predict([node_input, edge_index_input])\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810da1f6",
   "metadata": {},
   "source": [
    "Also layers can be further subclassed to create a GNN, for example of the message passing base layer. Where only `message_function` and `update_nodes` must be implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00f4ba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kgcnn.layers.message import MessagePassingBase\n",
    "from kgcnn.layers.modules import Dense\n",
    "\n",
    "class MyMessageNN(MessagePassingBase):\n",
    "\n",
    "    def __init__(self, units=10, **kwargs):\n",
    "        super(MyMessageNN, self).__init__(**kwargs)\n",
    "        self.dense = Dense(units)\n",
    "        self.add = LazyConcatenate()\n",
    "\n",
    "    def message_function(self, inputs, **kwargs):\n",
    "        n_in, n_out, edges = inputs\n",
    "        return self.dense(n_out)\n",
    "\n",
    "    def update_nodes(self, inputs, **kwargs):\n",
    "        nodes, nodes_update = inputs\n",
    "        return self.add([nodes, nodes_update])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73f97cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, None, 13])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note MyMessageNN is type only type layer.\n",
    "message_layer = MyMessageNN()\n",
    "out = message_layer([node_input, _, edge_index_input])\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ac5472",
   "metadata": {},
   "source": [
    "## Loading options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5397e58",
   "metadata": {},
   "source": [
    "There are many options to load data to a keras model, which depend on the size and location of the data to pass to the model. There may differences in speed and utility depending on the loading method. For more examples, please find https://github.com/aimat-lab/gcnn_keras/blob/master/notebooks/tutorial_model_loading_options.ipynb ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0348cb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_config = [\n",
    "    {\"shape\": (None, 3), \"name\": \"node_input\", \"dtype\": \"float32\", \"ragged\": True},\n",
    "    {\"shape\": (None, 2), \"name\": \"edge_index_input\", \"dtype\": \"int64\", \"ragged\": True}\n",
    "]\n",
    "output_config = {\"shape\": [], \"name\": \"graph_labels\", \"dtype\": \"float32\", \"ragged\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a6862f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = message_functional\n",
    "model.compile(loss=\"mean_absolute_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228ddfaa",
   "metadata": {},
   "source": [
    "#### 1. Tensor Input\n",
    "\n",
    "Tensor constants like the example above can be used as model input for data that comfortably fits into memory.\n",
    "The `kgcnn.data.base.MemoryGraphList` has a `tensor()` method to generate a tensor from a list of properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3edbf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MemoryGraphList [{'node_input': array([[0., 1., 0.],\n",
      "       [0., 0., 2.]]), 'edge_index_input': array([[0, 1],\n",
      "       [1, 0]]), 'graph_labels': array([1.])} ...]>\n"
     ]
    }
   ],
   "source": [
    "from kgcnn.data.base import MemoryGraphList\n",
    "dataset = MemoryGraphList([{\"node_input\": n, \"edge_index_input\": ei, \"graph_labels\": g} for n, ei, g in zip(nodes, idx, labels)])\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7d95dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\anaconda3\\envs\\gcnn_keras_test\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/pooling_local_edges/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/pooling_local_edges/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/pooling_local_edges/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 653ms/step - loss: 0.7880\n"
     ]
    }
   ],
   "source": [
    "tensor_input = dataset.tensor(input_config)\n",
    "tensor_output = dataset.tensor(output_config)\n",
    "out = model.fit([node_input, edge_index_input], tensor_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf2e788",
   "metadata": {},
   "source": [
    "#### 2. Keras Sequence\n",
    "\n",
    "For example `GraphBatchLoader` that inherits from `ks.utils.Sequence` and takes an iterable data object of type `list[dict]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6825f74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kgcnn.io.loader import GraphBatchLoader\n",
    "loader = GraphBatchLoader(data=dataset, inputs=input_config, outputs=output_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04f01885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 392ms/step - loss: 0.7661\n"
     ]
    }
   ],
   "source": [
    "out = model.fit(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f4c9a1",
   "metadata": {},
   "source": [
    "####  3. TF Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3818874",
   "metadata": {},
   "source": [
    "With tensorflow data and datasets. Again assuming given a list of indices and node properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5faf34a",
   "metadata": {},
   "source": [
    "* `from_tensor_slices`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f1df440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=((RaggedTensorSpec(TensorShape([None, None, 3]), tf.float32, 1, tf.int64), RaggedTensorSpec(TensorShape([None, None, 2]), tf.int64, 1, tf.int64)), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_x = tf.data.Dataset.from_tensor_slices((\n",
    "    tf.ragged.constant(nodes, ragged_rank=1, dtype=\"float32\"),\n",
    "    tf.ragged.constant(idx, ragged_rank=1, dtype=\"int64\")))\n",
    "ds_y = tf.data.Dataset.from_tensor_slices(tf.constant(labels))\n",
    "ds = tf.data.Dataset.zip((ds_x, ds_y))\n",
    "ds.batch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35880fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x211cd65c9d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ds.batch(3), epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d5a20f",
   "metadata": {},
   "source": [
    "* `from_generator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d45900b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ZipDataset element_spec=((RaggedTensorSpec(TensorShape([None, None, 3]), tf.float32, 1, tf.int64), RaggedTensorSpec(TensorShape([None, None, 2]), tf.int64, 1, tf.int64)), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 3\n",
    "data_length = 3\n",
    "def gen():\n",
    "    for i in range(0, data_length, batch_size):\n",
    "        yield (tf.ragged.constant(nodes[i:i+batch_size], dtype=\"float32\", ragged_rank=1), \n",
    "               tf.ragged.constant(idx[i:i+batch_size], dtype=\"int64\", ragged_rank=1))\n",
    "    \n",
    "ds_x_batch = tf.data.Dataset.from_generator(\n",
    "    gen,\n",
    "    output_signature=(\n",
    "        tf.RaggedTensorSpec(shape=(None, None, 3), ragged_rank=1, dtype=\"float32\"),\n",
    "        tf.RaggedTensorSpec(shape=(None, None, 2), ragged_rank=1, dtype=\"int64\")\n",
    "    )\n",
    ")\n",
    "ds_y_batch = tf.data.Dataset.from_tensor_slices(tf.constant(labels)).batch(batch_size)\n",
    "ds_batch = tf.data.Dataset.zip((ds_x_batch, ds_y_batch))\n",
    "ds_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "762560ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 909ms/step - loss: 0.7375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2124ca06670>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ds_batch, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c22d3bc",
   "metadata": {},
   "source": [
    "* `tf.data.experimental.dense_to_ragged_batch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "699105c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ZipDataset element_spec=((RaggedTensorSpec(TensorShape([None, None, 3]), tf.float32, 1, tf.int64), RaggedTensorSpec(TensorShape([None, None, 2]), tf.int64, 1, tf.int64)), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bath_size = 3\n",
    "dataset_list = []\n",
    "\n",
    "ds_node = tf.data.Dataset.from_generator(\n",
    "    lambda: [tf.constant(x) for x in nodes], \n",
    "    output_signature=tf.TensorSpec(shape=(None, 3), dtype=\"float32\")\n",
    ").apply(tf.data.experimental.dense_to_ragged_batch(batch_size=bath_size, drop_remainder=False))\n",
    "ds_edge = tf.data.Dataset.from_generator(\n",
    "    lambda: [tf.constant(x) for x in idx], \n",
    "    output_signature=tf.TensorSpec(shape=(None, 2), dtype=\"int64\")\n",
    ").apply(tf.data.experimental.dense_to_ragged_batch(batch_size=bath_size, drop_remainder=False))\n",
    "\n",
    "\n",
    "ds_x_batch = tf.data.Dataset.zip((ds_node, ds_edge))\n",
    "ds_y_batch = tf.data.Dataset.from_tensor_slices(tf.constant(graph_labels)).batch(batch_size)\n",
    "\n",
    "ds_batch = tf.data.Dataset.zip((ds_x_batch, ds_y_batch))\n",
    "ds_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e54e1fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2124ca0c700>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ds_batch, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bae156e",
   "metadata": {},
   "source": [
    "or via explicit generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ca2d1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ZipDataset element_spec=((RaggedTensorSpec(TensorShape([None, None, 3]), tf.float32, 1, tf.int64), RaggedTensorSpec(TensorShape([None, None, 2]), tf.int64, 1, tf.int64)), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen():\n",
    "    for i in range(len(nodes)):\n",
    "        yield nodes[i], idx[i]\n",
    "\n",
    "ds_x_batch = tf.data.Dataset.from_generator(\n",
    "    gen, output_signature=(tf.TensorSpec(shape=(None, 3), dtype=\"float32\"),tf.TensorSpec(shape=(None, 2), dtype=\"int64\"))\n",
    ").apply(tf.data.experimental.dense_to_ragged_batch(batch_size=bath_size, drop_remainder=False))\n",
    "\n",
    "ds_y_batch = tf.data.Dataset.from_tensor_slices(tf.constant(graph_labels)).batch(batch_size)\n",
    "\n",
    "ds_batch = tf.data.Dataset.zip((ds_x_batch, ds_y_batch))\n",
    "ds_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed4ca066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2124ca0c1c0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ds_batch, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18be89df",
   "metadata": {},
   "source": [
    "> **NOTE**: You can find this page as jupyter notebook in https://github.com/aimat-lab/gcnn_keras/tree/master/docs/source"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
